# Main entrypoint of the workflow.
# Please follow the best practices:
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there.

# Possible values are 'NA' (North Atlantic), 'SA' (South Atlantic), 'EP' (Eastern North Pacific, which includes                                                the Central Pacific region), 'WP' (Western North Pacific), 'SP' (South Pacific), 'SI' (South Indian), 'NI' (North Indian).
basins = ["NA", "EP", "WP", "SP", "SI", "NI"]  # Replace with actual basin names

config["start"] = 1980
config["end"] = 2023
config["nsynth"] = 25
config["higher_res_surge"] = 0.008

years = list(range(config["start"], config["end"], 1))


rule create_centroids:
    output:
        "global_centroids.hdf5",
    log:
        "logs/create_centroids.log",
    resources:
        mem_mb_per_cpu=12000,
    conda:
        "climada_env_TC"
    script:
        "scripts/create_centroids.py"


rule tracks_basin_year:
    output:
        "tracks/{basin}/IBTracs_{basin}_{year}.hdf5",
    params:
        timestep=1,
    wildcard_constraints:
        basin="[A-Z]+",
        year="[0-9]{4}",
    conda:
        "climada_env_TC"
    resources:
        mem_mb_per_cpu=8000,
        runtime=240,
    log:
        "logs/find_tracks_{basin}_{year}.log",
    script:
        "scripts/find_tracks_basin_year.py"


def synth_track_memb(wildcards, attempt):
    return 1000 * (config["nsynth"] // 2) * attempt


rule synth_tracks_basin_year:
    input:
        "tracks/{basin}/IBTracs_{basin}_{year}.hdf5",
    output:
        "tracks/{basin}/IBTracs_synth_{basin}_{year}.hdf5",
    wildcard_constraints:
        basin="[A-Z]+",
        year="[0-9]{4}",
    params:
        nsynth=config["nsynth"],
    conda:
        "climada_env_TC"
    resources:
        mem_mb_per_cpu=synth_track_memb,
        runtime=240,
    log:
        "logs/generate_synths_tracks_{basin}_{year}.log",
    script:
        "scripts/generate_synths_tracks_basin_year.py"


checkpoint tcs_split_basin_year_tracks:
    input:
        tracks="tracks/{basin}/IBTracs_synth_{basin}_{year}.hdf5",
    output:
        directory("tracks/{basin}/{year}/synth_splits/"),
    params:
        max_tracks=config["max_tracks_per_split"],
    conda:
        "climada_env_TC"
    resources:
        mem_mb_per_cpu=8000,
        runtime=240,
    log:
        "logs/split_synth_tracks_{basin}_{year}.log",
    script:
        "scripts/split_synth_tracks.py"


rule tcs_basin_year_split:
    input:
        tracks="tracks/{basin}/{year}/synth_splits/IBTracs_synth_{basin}_{year}_split_{i}.hdf5",
        centroids="global_centroids.hdf5",
    output:
        "tropcyc/{basin}/TCs_{basin}_{year}_split_{i}.hdf5",
    params:
        buf=5,
        max_memory_gb=14,
    conda:
        "climada_env_TC"
    resources:
        mem_mb_per_cpu=16000,
        runtime=240,
    log:
        "logs/generate_TCs_{basin}_{year}_split_{i}.log",
    script:
        "scripts/generate_TCs_basin_year.py"


rule surges_basin_year_split:
    input:
        tropcyc="tropcyc/{basin}/TCs_{basin}_{year}_split_{i}.hdf5",
        slr=expand(
            "{slr_data}/{{ssp}}/total_{{ssp}}_medium_confidence_values.nc",
            slr_data=config["slr_data_path"],
        ),
        dem=config["dem_topo_path"],
    output:
        "surge/{basin}/TCSurges_{ssp}_{slr_year}slr_{basin}_{year}_split_{i}.hdf5",
    wildcard_constraints:
        basin="[A-Z]+",
        year="[0-9]{4}",
        ssp="ssp119|ssp126|ssp245|ssp370|ssp585",
        slr_year="20[2-9]0|21[0-5]0",
    params:
        higher_res=config["higher_res_surge"],
    conda:
        "climada_env_TC"
    resources:
        mem_mb_per_cpu=16000,
        runtime=240,
    log:
        "logs/generate_TCs_{ssp}_{slr_year}slr_{basin}_{year}_{i}.log",
    script:
        "scripts/generate_TCs_surges_basin_year.py"


def aggregate_tcs(wildcards):
    checkpoint_output = checkpoints.tcs_split_basin_year_tracks.get(**wildcards).output[
        0
    ]
    return expand(
        "tropcyc/{{basin}}/TCs_{{basin}}_{{year}}_split_{i}.hdf5",
        i=glob_wildcards(
            os.path.join(
                checkpoint_output, "IBTracs_synth_{{basin}}_{{year}}_split_{i}.hdf5"
            )
        ).i,
    )


def aggregate_surges(wildcards):
    checkpoint_output = checkpoints.tcs_split_basin_year_tracks.get(**wildcards).output[
        0
    ]
    return expand(
        "surge/{{basin}}/TCSurges_{{ssp}}_{{slr_year}}slr_{{basin}}_{{year}}_split_{i}.hdf5",
        i=glob_wildcards(
            os.path.join(
                checkpoint_output, "IBTracs_synth_{{basin}}_{{year}}_split_{i}.hdf5"
            )
        ).i,
    )


rule gather_split_tcs:
    input:
        aggregate_tcs,
    output:
        "tropcyc/{basin}/TCs_{basin}_{year}.hdf5",
    conda:
        "climada_env_TC"
    resources:
        mem_mb_per_cpu=16000,
        runtime=240,
    log:
        "logs/gather_split_TCs_{basin}_{year}.log",
    script:
        "scripts/concatenate_all_basins_tcs.py"


rule gather_split_surges:
    input:
        aggregate_surges,
    output:
        "surge/{basin}/TCSurges_{ssp}_{slr_year}slr_{basin}_{year}.hdf5",
    conda:
        "climada_env_TC"
    resources:
        mem_mb_per_cpu=16000,
        runtime=240,
    log:
        "logs/gather_split_TCSurges_{ssp}_{slr_year}slr_{basin}_{year}.log",
    script:
        "scripts/gather_split_surges.py"


rule concatenate_all_years_tcs:
    input:
        expand("tropcyc/{{basin}}/TCs_{{basin}}_{year}.hdf5", year=years),
    output:
        expand(
            "tropcyc/{{basin}}/TCs_{{basin}}_{start}_{end}.hdf5",
            start=config["start"],
            end=config["end"],
        ),
    wildcard_constraints:
        basin="[A-Z]+",
    resources:
        mem_mb_per_cpu=24000,
    conda:
        "climada_env_TC"
    log:
        "logs/concatenate_all_years_tcs_{basin}.log",
    script:
        "scripts/concatenate_all_years_tcs.py"


rule concatenate_all_basins_tcs:
    input:
        expand("tropcyc/{basin}/TCs_{basin}_1980_2023.hdf5", basin=basins),
    output:
        "tropcyc/all_basins_1980_2023.hdf5",
    conda:
        "climada_env_TC"
    resources:
        mem_mb_per_cpu=24000,
    log:
        "logs/concatenate_all_basins_tcs.log",
    script:
        "scripts/concatenate_all_basins_tcs.py"
